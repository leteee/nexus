# Nexus Video Data Replay Template
# Demonstrates overlaying time-series data onto video frames

case_info:
  name: "Vehicle Data Replay"
  description: "Extract frames, render speed and ADB target data overlay, compose output video"
  version: "3.0.0"

pipeline:
  # Step 1: Extract frames from video
  - plugin: "Video Splitter"
    config:
      video_path: "input/synthetic_driving.mp4"
      output_dir: "temp/frames"
      frame_pattern: "frame_{:06d}.png"

  # Step 2: Render data onto frames using modular renderers
  - plugin: "Data Renderer"
    config:
      # Time range control (Time is first-class: video timeline is primary)
      # start_time: null  # Start time: null (default), timestamp_ms, or "2025-10-27 12:00:00"
      # end_time: null    # End time: null (default), timestamp_ms, or "2025-10-27 12:01:00"
      start_time: "2025-10-27 08:30:10"
      end_time: "2025-10-27 08:30:30"
      frames_dir: "temp/frames"
      output_dir: "temp/rendered_frames"
      frame_pattern: "frame_{:06d}.png"
      timestamps_path: "input/vehicle_timeline.csv"  # Real frame acquisition timestamps

      # New format: Multiple renderers (each handles one data type)
      renderers:
        # Render vehicle speed (top-left corner)
        - class: "nexus.contrib.repro.renderers.SpeedRenderer"
          kwargs:
            time_offset_ms: 0  # Time offset: adjust data timeline (0=no offset)
            data_path: "input/speed.jsonl"
            position: [30, 60]
            tolerance_ms: 5000.0  # Forward matching: hold speed up to 5s
            font_scale: 1.2
            color: [0, 255, 0]  # Green

        # Render 3D target detections (projected to 2D)
        - class: "nexus.contrib.repro.renderers.TargetRenderer"
          kwargs:
            time_offset_ms: 0  # Time offset: adjust data timeline (0=no offset)
            data_path: "input/adb_targets.jsonl"
            calibration_path: "../../src/nexus/contrib/repro/camera_calibration.json"
            tolerance_ms: 50.0  # Nearest matching: within 50ms
            box_color: [0, 255, 0]  # Green boxes
            show_panel: true

  # Step 3: Compose rendered frames back to video
  - plugin: "Video Composer"
    config:
      frames_dir: "temp/rendered_frames"
      output_path: "output/vehicle_replay.mp4"
      fps: 30.0
      frame_pattern: "frame_{:06d}.png"
      codec: "mp4v"

# Architecture Notes:
#
# 1. Modular Renderers:
#    - Each renderer handles ONE data type
#    - SpeedRenderer: Vehicle speed with forward matching
#    - TargetRenderer: 3D object detection with projection
#
# 2. Easy to Extend:
#    - Add new data type: Create a renderer class
#    - Inherit from BaseDataRenderer
#    - Implement render(frame, timestamp_ms)
#    - Add to renderers list above
#
# 3. Matching Strategies:
#    - Forward: Use most recent data ≤ timestamp (good for speed, GPS)
#    - Nearest: Use closest data point (good for high-freq like targets)
#    - Backward: Use earliest data ≥ timestamp (for predictive data)
#
# 4. Data Flow:
#    Video → Frames → [Renderer 1] → [Renderer 2] → ... → Rendered Frames → Video
#    Each renderer applies its visualization sequentially
#
# Example: Adding GPS Renderer
#
# renderers:
#   - class: "nexus.contrib.repro.renderers.SpeedRenderer"
#     kwargs: { ... }
#
#   - class: "nexus.contrib.repro.renderers.TargetRenderer"
#     kwargs: { ... }
#
#   - class: "myproject.GPSRenderer"  # Custom renderer
#     kwargs:
#       data_path: "input/gps.jsonl"
#       position: [20, 100]
#       tolerance_ms: 1000
#

